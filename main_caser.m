clear; clc;

%% dataset related arguments
train_path = 'data/ml1m/test/train.txt';
test_path = 'data/ml1m/test/test.txt';
rate_once = 1;           % whether each item will only be rated once by each user
L = 5;                   % length of sequence
T = 3;                   % number of targets

%% training arguments
seed = 1234;             % random seed
n_iter = 50;             % number of iteration
learning_rate = 1e-3;    % learning rate for ADAM
l2 = 1e-6;               % l2 norm weight
neg_samples = 3;         % negative samples per target
early_stop = true;       % whether to perform early stop during training

%% Caser related arguments
d = 50;                 % number of latent dimensions
nv = 4;                 % number of vertical filters
nh = 16;                % number of horizontal filters
ac_conv = 'relu';       % activation function for convolution layer (i.e., phi_c in paper)
ac_fc = 'relu';         % activation function for fully-connected layer (i.e., phi_a in paper)
drop_rate = 0.5;        % drop ratio when performing dropout

%% Perform training
args = struct(...
        'trainpath',train_path,...
        'testpath',test_path,...    
        'rateonce',rate_once,...    
        'L',L,...
        'T', T,...
        'seed',seed,...
        'niter',n_iter,...
        'lrate',learning_rate,...
        'l2',l2,...
        'negsample',neg_samples,...    
        'earlystop',early_stop,...    
        'd',d,...
        'nv',nv,...                
        'nh',nh,...
        'acconv',ac_conv,...
        'acfc',ac_fc,...
        'droprate',drop_rate...
        );

caser_train(args);
